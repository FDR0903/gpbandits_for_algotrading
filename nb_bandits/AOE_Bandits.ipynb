{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11539250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from   IPython.display import display, HTML\n",
    "from collections import deque\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import datetime\n",
    "from scipy import interpolate\n",
    "import math\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as md\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib.dates as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_module_path = os.path.abspath(os.path.join('..'))\n",
    "if parent_module_path not in sys.path:\n",
    "    sys.path.append(parent_module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305f946a",
   "metadata": {},
   "source": [
    "# Load Data & Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AOE.utils import get_LOB_data, get_LOB_features, get_meta_order_df, verbose_print\n",
    "from AOE.plots import rescale_plot\n",
    "from AOE.plots import hit_ratio_analysis, reward_distribution_analysis, regret_plots, analyze_meta_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604dceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path     = pathlib.Path(os.path.abspath(os.path.join('..')), \"data\", \"Market\")\n",
    "reward_path   = pathlib.Path(os.path.abspath(os.path.join('..')), \"data\", \"Rewards\")\n",
    "feature_path  = pathlib.Path(os.path.abspath(os.path.join('..')), \"data\", \"Features\")\n",
    "\n",
    "asset_name    = \"MSFT\"\n",
    "tick_size     = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67922ba8-c1e9-4fa2-ab06-280cdbf6026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = None\n",
    "\n",
    "for trade_day in ('01', '02'):#, '03', '06', '07', '08', '09', '10', '13', '14', '16', '17', '21', '22', '23', '24', '27', '28', '29', '30'):\n",
    "    trade_date    = f'2022-06-{trade_day}'\n",
    "    print('Reading', trade_date)\n",
    "    if False:\n",
    "        LOB_data, LOB_messages     = get_LOB_data(data_path, asset_name, trade_date)\n",
    "        LOB_features  = get_LOB_features(LOB_data,\n",
    "                                         trade_date = trade_date,\n",
    "                                         trend      = ({'w' : 25},),\n",
    "                                         vol        = ({'w' : 500}, {'w' : 1000}, \n",
    "                                                       {'w' : 5000}, {'w' : 20000}),\n",
    "                                         depth      = {'w' : 500},\n",
    "                                         LOB_msg    = LOB_messages)\n",
    "        LOB_features.to_pickle(f'../data/Features/LOB_features_{trade_date}.pkl')\n",
    "    else:\n",
    "        LOB_features = pd.read_pickle(f'../data/Features/LOB_features_{trade_date}.pkl')\n",
    "    \n",
    "    # take data every 10 trades\n",
    "    LOB_features = LOB_features.iloc[::10,:].set_index('timestamp')\n",
    "    \n",
    "    if all_data is None: \n",
    "        all_data = LOB_features\n",
    "    else:\n",
    "        # LOB_features.index = LOB_features.index #+ (all_data.index.values[-1] - LOB_features.index.values[0])\n",
    "        all_data = pd.concat((all_data, LOB_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429b209-68ce-4bf9-9acf-944a94859412",
   "metadata": {},
   "source": [
    "# Optimal Strategies & Trading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cb83a-fa3d-4b09-96fa-85cc815c86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['LT'] = (-(all_data['rsi_5_10000']-50)/6)\n",
    "LOB_features   = all_data.dropna().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5e89e-1371-424b-b03e-c9d0f93657c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies  = {'imbalance' : {'name'             : 'imbalance',\n",
    "                              'params'           : {'feature_name'     : 'imbalance_1',\n",
    "                                                      'estimation_period': '1min',\n",
    "                                                      'use_interpolator' : False,\n",
    "                                                      'alpha'            : 10, \n",
    "                                                      'phi'              : 0.001, \n",
    "                                                      'kappa'            : 9e-10},\n",
    "                                'contextual_params': {'feature_name'  : 'vol_50_50000'}},\n",
    "               \n",
    "               'trend' : {'name'             : 'imbalance',\n",
    "                            'params'           : {'feature_name'     : 'LT',\n",
    "                                                  'estimation_period': '1min', \n",
    "                                                  'use_interpolator' : False,\n",
    "                                                  'alpha'            : 10, \n",
    "                                                  'phi'              : 0.001, \n",
    "                                                  'kappa'            : 9e-10},\n",
    "                            'contextual_params': {'feature_name'  : 'vol_50_50000'}},\n",
    "               \n",
    "               'twap'        : {'name'             : 'TWAP',\n",
    "                                'params'           : {'feature_name'     : 'imbalance_3',\n",
    "                                                      'estimation_period': '1min', \n",
    "                                                      'use_interpolator' : False,\n",
    "                                                      'alpha'            : 10, \n",
    "                                                      'phi'              : 0.001, \n",
    "                                                      'kappa'            : 9e-10},\n",
    "                                'contextual_params': {'feature_name'  : 'vol_50_50000'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7daf5-e896-4e46-9e13-ba4ea7e938c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_intensity   = 0.001 # in trade time\n",
    "meta_order_size     = 100 # Fiwed size of every order\n",
    "latency             = 0   # TODO: implement this\n",
    "T                   = 60*10 # trading window for every order in seconds\n",
    "trading_frequency   = 3  # in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3598ff",
   "metadata": {},
   "source": [
    "# GP bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab7de2-d611-4e4c-86df-f4c30fe46ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AOE.gp_bandit import gp_bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e970f0c-5947-4dd7-a96c-3550675c0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood models & non stationarity params\n",
    "likelihood              = gpytorch.likelihoods.GaussianLikelihood()\n",
    "size_buffer             = 100 # in terms of number of rewards to sample from\n",
    "size_buffer_nts         = 60*10 # in terms of seconds of oobservation\n",
    "nb_intermediary_rewards = 5\n",
    "\n",
    "# Bandit objects\n",
    "bandits = {'TS'  : gp_bandit(strategies, likelihood, size_buffer, bandit_algo='TS'), \n",
    "           'UCB' : gp_bandit(strategies, likelihood, size_buffer, bandit_algo='UCB', bandit_params=0.1) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd52a8-1a9b-442c-9138-b05e67ce1388",
   "metadata": {},
   "source": [
    "# Other control parameters and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1edd5-a05e-4fe8-a4a9-3e2b3b94beb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# variables for historical bandit data\n",
    "pending_rewards           = {bandit_k: {} for bandit_k in bandits.keys() }\n",
    "pending_int_rewards       = {bandit_k: {} for bandit_k in bandits.keys() }\n",
    "pending_rewards['oracle'] = {}\n",
    "historical_rewards        = {bandit_k: [] for bandit_k in bandits.keys() }\n",
    "historical_strats         = {bandit_k: [] for bandit_k in bandits.keys() }\n",
    "historical_oracle_rewards = []\n",
    "historical_oracle_strats  = []\n",
    "historical_all_rewards    = []\n",
    "historical_reward_times   = []\n",
    "order_arrival_times       = []\n",
    "\n",
    "# variables for historical trading data\n",
    "tape_meta_orders          = deque(maxlen=None) # A tape with meta order objects\n",
    "meta_order_id_c           = 0 # counter to flag meta orders with IDs\n",
    "order_id_c                = 0 # counter to flag orders with IDs\n",
    "\n",
    "i_order                   = 0\n",
    "nb_added_rewards          = {bandit_k:0 for bandit_k in bandits.keys()}\n",
    "order_arrival_times       = LOB_features.dropna().iloc[::5,:].index.values # .timestamp.values\n",
    "tape_meta_orders          = deque(maxlen=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf66889-b3fd-4865-b74c-c97de1e84e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_level             = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db58e01-a058-4db6-9b9e-92cf5f1ec53a",
   "metadata": {},
   "source": [
    "# Trading simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87104b-eb15-4eae-8411-8ca3f95d59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AOE.order import order\n",
    "from AOE.meta_order import meta_order\n",
    "from AOE.strategy import strategy\n",
    "\n",
    "from AOE.stats import get_meta_order_df\n",
    "from AOE.stats import get_meta_order_details\n",
    "from AOE.plots import plot_meta_order\n",
    "\n",
    "from AOE.optimal_trading import execute_strategy\n",
    "from AOE.bandit_utils import update_reward_variables, update_bandit_variables\n",
    "from AOE.bandit_utils import pop_from_dict, execute_and_obtain_rewards, update_pending_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50db3e8-87e2-4854-8130-371315ff0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_arrival_time_indices = np.random.poisson(arrival_intensity, size=len(order_arrival_times))\n",
    "\n",
    "for (i_time, order_arrival_time) in enumerate(order_arrival_times): # leave a few minutes\n",
    "\n",
    "    ###############################################\n",
    "    # retrain GPs hyperparameters every N orders \n",
    "    ###############################################\n",
    "    retrain_hyperparameters = False\n",
    "    if i_order%10    == 0: retrain_hyperparameters=True\n",
    "    \n",
    "    ##################################################\n",
    "    # add pending delayed rewards to bandit objects\n",
    "    ##################################################\n",
    "    to_pops = update_reward_variables(order_arrival_time, \n",
    "                                      historical_oracle_rewards, historical_oracle_strats, historical_all_rewards, historical_reward_times,\n",
    "                                      pending_rewards, verbose_level)\n",
    "    \n",
    "    # Sanity check\n",
    "    if len(historical_rewards['TS'])!=len(historical_rewards['UCB']):\n",
    "        print('Intentional error !!')\n",
    "        fdff+1\n",
    "    \n",
    "    pop_from_dict(pending_rewards['oracle'], to_pops)\n",
    "    \n",
    "    for bandit_k in bandits.keys():\n",
    "        to_pops_int, to_pops = update_bandit_variables(pending_int_rewards, pending_rewards, bandits, bandit_k, \n",
    "                                                       order_arrival_time, \n",
    "                                                       verbose_level,\n",
    "                                                       retrain_hyperparameters, historical_rewards, historical_strats,\n",
    "                                                       nb_added_rewards)\n",
    "        pop_from_dict(pending_rewards[bandit_k], to_pops)\n",
    "        pop_from_dict(pending_int_rewards[bandit_k], to_pops_int)\n",
    "        \n",
    "\n",
    "    ##################################################\n",
    "    # if an order arrives: add intermediary\n",
    "    # and final rewards to pending list\n",
    "    ##################################################\n",
    "    if true_arrival_time_indices[i_time]>0:\n",
    "        # randomize buys and sells\n",
    "        buysell = 2*np.random.randint(0, 2, size=None, dtype=int)-1\n",
    "        \n",
    "        verbose_print(verbose_level, order_arrival_time, f'I received an order at {order_arrival_time} with quantity {buysell*meta_order_size}', True)\n",
    "        i_order          += 1\n",
    "        \n",
    "        ######################\n",
    "        # get feature values\n",
    "        ######################\n",
    "        feature_values = LOB_features.loc[order_arrival_time:].iloc[0,:].fillna(0.) # fillna should be controlled here ..\n",
    "        \n",
    "        ######################################\n",
    "        # select the strategy for all bandits\n",
    "        ######################################\n",
    "        verbose_print(verbose_level, order_arrival_time, f'Selecting strategies ...')\n",
    "        \n",
    "        best_strategies_bandits = {}\n",
    "        for bandit_k in bandits.keys():\n",
    "            if nb_added_rewards[bandit_k] < 5: # at least 5 rewards before sampling\n",
    "                best_strategies_bandits[bandit_k]  = random.choice(list(strategies.keys()))\n",
    "            else:\n",
    "                best_strategies_bandits[bandit_k]  = bandits[bandit_k].select_best_strategy(feature_values)\n",
    "        \n",
    "        verbose_print(verbose_level, order_arrival_time, f'Selected strategies: {best_strategies_bandits}')\n",
    "\n",
    "        ######################################\n",
    "        # Execute all available strategies \n",
    "        ######################################\n",
    "        order_id_c, meta_order_id_c, reward_info, all_strats_rewards, \\\n",
    "        best_oracle_reward, best_oracle_strategy = execute_and_obtain_rewards(tape_meta_orders, order_id_c, meta_order_id_c, strategies, \n",
    "                                                                              LOB_features, order_arrival_time, \n",
    "                                                                              T, trading_frequency, buysell*meta_order_size, \n",
    "                                                                              latency, trade_date, verbose_level, nb_intermediary_rewards)\n",
    "        \n",
    "        \n",
    "        ######################################\n",
    "        # add intermediary and final rewards of\n",
    "        # selected strategies of bandits\n",
    "        ######################################\n",
    "        update_pending_rewards(pending_int_rewards, pending_rewards, \n",
    "                               bandits, best_strategies_bandits, reward_info, \n",
    "                               feature_values, strategies,\n",
    "                               best_oracle_strategy, best_oracle_reward, order_arrival_time, all_strats_rewards)\n",
    "\n",
    "        \n",
    "        verbose_print(verbose_level, order_arrival_time, f\"Oracle strategy: {best_oracle_strategy}\")\n",
    "    \n",
    "    if i_order%3   == 0: clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b1aa5-44ad-4113-a009-39c6526c33fb",
   "metadata": {},
   "source": [
    "# Regret analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a9038-b857-484f-84d2-574b27164ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical rewards and regret\n",
    "rewards_to_plot = pd.DataFrame(index=historical_reward_times)\n",
    "regrets_to_plot = pd.DataFrame(index=historical_reward_times)\n",
    "\n",
    "for bandit_k in bandits.keys():\n",
    "    regrets_to_plot[bandit_k] = - np.array(historical_rewards[bandit_k]) + np.array(historical_oracle_rewards)\n",
    "for (i_strat, strat) in enumerate(strategies.keys()):\n",
    "    regrets_to_plot[strat]    = - np.array(historical_all_rewards)[:,i_strat] + np.array(historical_oracle_rewards)\n",
    "\n",
    "for bandit_k in bandits.keys():\n",
    "    rewards_to_plot[bandit_k] = np.array(historical_rewards[bandit_k])\n",
    "for (i_strat, strat) in enumerate(strategies.keys()):\n",
    "    rewards_to_plot[strat]    = np.array(historical_all_rewards)[:,i_strat] \n",
    "\n",
    "regrets_to_plot = regrets_to_plot.sort_index()\n",
    "rewards_to_plot = rewards_to_plot.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9206bf9-df12-49ee-80ba-377ba3220557",
   "metadata": {},
   "source": [
    "### Hit ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1847c05-86b4-4a4b-b43e-48753a19c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_ratio_analysis(historical_strats, bandits, historical_oracle_strats, _W = 5.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05251370-7e08-47ea-9317-2f950dbb7fd5",
   "metadata": {},
   "source": [
    "### Reward distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a111ff4-79f8-4d15-98f9-2590ebb2db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_to_plot.TS.hist(bins=100, color='b', alpha=0.7)\n",
    "rewards_to_plot.UCB.hist(bins=100, color='g', alpha=0.7)\n",
    "rewards_to_plot.imbalance.hist(bins=100, color='grey', alpha=0.7)\n",
    "\n",
    "plt.ylim(0, 10)\n",
    "plt.legend(['TS', 'UCB', 'imbalance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1fd62-48c5-4c37-936f-da7d21fb0ea3",
   "metadata": {},
   "source": [
    "### Reward distributions in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4a8d1-fc9d-44d6-8ffa-19dee300649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_est  = 5 # in number of rewards, can be \"10min\"\n",
    "bandit_name = 'TS'\n",
    "\n",
    "reward_distribution_analysis(bandit_name, bandits, period_est, LOB_features, rewards_to_plot, historical_reward_times, \n",
    "                                 historical_strats, historical_oracle_strats, strategies, W = 7, figure_name = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c490e-d00a-4dce-940c-1089aa13b479",
   "metadata": {},
   "source": [
    "### Regret plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affd7c9-5153-4427-99fc-5cc4bd820ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_plots(strategies, historical_reward_times, regrets_to_plot, LOB_features, bandits, W=5.5, figure_name = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f006b-e67b-4a2f-a5b1-77cb32bd368c",
   "metadata": {},
   "source": [
    "### Analyze a given specific order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d539648-7d08-48a7-a9c9-f400331f3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_order_id = 12\n",
    "analyze_meta_order(meta_order_id, tape_meta_orders, W=5.8, figure_name = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62722035-f9ae-4f20-bc69-cee9f4cd105d",
   "metadata": {},
   "source": [
    "### GP plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f8019-4650-48ae-b2b2-18d505bb5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_name  = 'TS'\n",
    "feature_name = 'vol_50_50000'\n",
    "\n",
    "bandits[bandit_name].plot_fit_all(lv=LOB_features[feature_name].min(), \n",
    "                                  uv=LOB_features[feature_name].max(), plot_path=None, W=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
